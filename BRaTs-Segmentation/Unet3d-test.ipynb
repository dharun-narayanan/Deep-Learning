{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "The Dataset chosen was Brain Tumor Segmentation(BraTS2020) : https://www.kaggle.com/datasets/awsaf49/brats2020-training-data .\n",
    "Given Dataset contains Brain tumour segmentation multimodal scans which are in NIfTI file format (.nii.gz) and describe different volumes like \n",
    "1. native (T1)\n",
    "2. post-contrast T1-weighted (T1Gd)\n",
    "3. T2-weighted (T2)\n",
    "4. T2 Fluid Attenuated Inversion Recovery (T2-FLAIR)\n",
    "\n",
    "Tumour annotations comprise of : \n",
    "1. necrotic and non-enhancing tumor core (NCR/NET — label 1)\n",
    "2. peritumoral edema (ED — label 2)\n",
    "3. GD-enhancing tumor (ET — label 4)\n",
    "\n",
    "### Formulation :\n",
    "+ Each pixel must be labeled “1” if it is part of one of the classes (NCR/NET — label 1, ED — label 2, ET — label 4), and “0” if not.\n",
    "\n",
    "### Solution\n",
    "+ Unet3d will be used for automatic segmentation / mask generation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install nibabel\n",
    "# !pip install pydicom\n",
    "# !pip install nilearn\n",
    "# !pip install albumentations==0.4.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T10:56:47.951147Z",
     "iopub.status.busy": "2023-06-02T10:56:47.950462Z",
     "iopub.status.idle": "2023-06-02T10:56:55.220823Z",
     "shell.execute_reply": "2023-06-02T10:56:55.219875Z",
     "shell.execute_reply.started": "2023-06-02T10:56:47.951108Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "import time\n",
    "from random import randint\n",
    " \n",
    "import gc \n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import nibabel as nib\n",
    "import pydicom as pdm\n",
    "import nilearn as nl\n",
    "import nilearn.plotting as nlplt\n",
    "import h5py\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import matplotlib.animation as anim\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "import seaborn as sns\n",
    "import imageio\n",
    "from skimage.transform import resize\n",
    "from skimage.util import montage\n",
    "\n",
    "from IPython.display import Image as show_gif\n",
    "from IPython.display import clear_output\n",
    "from IPython.display import YouTubeVideo\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.nn import MSELoss\n",
    "\n",
    "# !pip install albumentations==0.4.6\n",
    "import albumentations as A\n",
    "# from albumentations.pytorch import ToTensor, ToTensorV2\n",
    "\n",
    "\n",
    "from albumentations import Compose, HorizontalFlip\n",
    "# from albumentations.pytorch import ToTensor, ToTensorV2 \n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "print(torch.cuda.device_count())\n",
    "\n",
    "(torch.cuda.current_device())\n",
    "\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T10:56:55.223152Z",
     "iopub.status.busy": "2023-06-02T10:56:55.222787Z",
     "iopub.status.idle": "2023-06-02T10:56:55.229278Z",
     "shell.execute_reply": "2023-06-02T10:56:55.228091Z",
     "shell.execute_reply.started": "2023-06-02T10:56:55.223121Z"
    }
   },
   "outputs": [],
   "source": [
    "# code wall time starts(cw0)\n",
    "cw0 = time.time() \n",
    "\n",
    "# data loading time starts(dl0)\n",
    "dl0 = time.time() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T10:56:55.232583Z",
     "iopub.status.busy": "2023-06-02T10:56:55.231552Z",
     "iopub.status.idle": "2023-06-02T10:56:55.272060Z",
     "shell.execute_reply": "2023-06-02T10:56:55.271203Z",
     "shell.execute_reply.started": "2023-06-02T10:56:55.232516Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_filename = \"./dataset/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_001/BraTS20_Training_001_flair.nii\"\n",
    "sample_filename_mask = \"./dataset/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_001/BraTS20_Training_001_seg.nii\"\n",
    "\n",
    "\n",
    "sample_img = nib.load(sample_filename)\n",
    "sample_img = np.asanyarray(sample_img.dataobj)\n",
    "sample_img = np.rot90(sample_img)\n",
    "sample_mask = nib.load(sample_filename_mask)\n",
    "sample_mask = np.asanyarray(sample_mask.dataobj)\n",
    "sample_mask = np.rot90(sample_mask)\n",
    "print(\"img shape ->\", sample_img.shape)\n",
    "print(\"mask shape ->\", sample_mask.shape)\n",
    "\n",
    "#load --> conversion to array --> rotate 90 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-06-02T10:56:55.274961Z",
     "iopub.status.busy": "2023-06-02T10:56:55.274623Z",
     "iopub.status.idle": "2023-06-02T10:56:55.454473Z",
     "shell.execute_reply": "2023-06-02T10:56:55.453545Z",
     "shell.execute_reply.started": "2023-06-02T10:56:55.274929Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_filename2 = './dataset/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_001/BraTS20_Training_001_t1.nii'\n",
    "sample_img2 = nib.load(sample_filename2)\n",
    "sample_img2 = np.asanyarray(sample_img2.dataobj)\n",
    "sample_img2  = np.rot90(sample_img2)\n",
    "\n",
    "sample_filename3 = './dataset/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_001/BraTS20_Training_001_t2.nii'\n",
    "sample_img3 = nib.load(sample_filename3)\n",
    "sample_img3 = np.asanyarray(sample_img3.dataobj)\n",
    "sample_img3  = np.rot90(sample_img3)\n",
    "\n",
    "sample_filename4 = './dataset/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_001/BraTS20_Training_001_t1ce.nii'\n",
    "sample_img4 = nib.load(sample_filename4)\n",
    "sample_img4 = np.asanyarray(sample_img4.dataobj)\n",
    "sample_img4  = np.rot90(sample_img4)\n",
    "\n",
    "# WHOLE TUOMUR / ED - LABEL 2 \n",
    "mask_WT = sample_mask.copy()\n",
    "mask_WT[mask_WT == 1] = 1\n",
    "mask_WT[mask_WT == 2] = 1\n",
    "mask_WT[mask_WT == 4] = 1\n",
    "\n",
    "# NCR OR NET - LABEL 1 \n",
    "mask_TC = sample_mask.copy()\n",
    "mask_TC[mask_TC == 1] = 1\n",
    "mask_TC[mask_TC == 2] = 0\n",
    "mask_TC[mask_TC == 4] = 1\n",
    "\n",
    "# ET - LABEL 4 \n",
    "mask_ET = sample_mask.copy()\n",
    "mask_ET[mask_ET == 1] = 0\n",
    "mask_ET[mask_ET == 2] = 0\n",
    "mask_ET[mask_ET == 4] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T10:56:55.456994Z",
     "iopub.status.busy": "2023-06-02T10:56:55.456269Z",
     "iopub.status.idle": "2023-06-02T10:56:55.463502Z",
     "shell.execute_reply": "2023-06-02T10:56:55.462341Z",
     "shell.execute_reply.started": "2023-06-02T10:56:55.456960Z"
    }
   },
   "outputs": [],
   "source": [
    "# total data loading time(dlt) \n",
    "dl1 = time.time() \n",
    "dlt = dl1 - dl0\n",
    "print(\"Data loading time : \", dlt )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-06-02T10:56:55.465554Z",
     "iopub.status.busy": "2023-06-02T10:56:55.465253Z",
     "iopub.status.idle": "2023-06-02T10:56:58.139340Z",
     "shell.execute_reply": "2023-06-02T10:56:58.138479Z",
     "shell.execute_reply.started": "2023-06-02T10:56:55.465510Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://matplotlib.org/3.3.2/gallery/images_contours_and_fields/plot_streamplot.html#sphx-glr-gallery-images-contours-and-fields-plot-streamplot-py\n",
    "# https://stackoverflow.com/questions/25482876/how-to-add-legend-to-imshow-in-matplotlib\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "\n",
    "gs = gridspec.GridSpec(nrows=2, ncols=4, height_ratios=[1, 1.5])\n",
    "\n",
    "#  Varying density along a streamline\n",
    "ax0 = fig.add_subplot(gs[0, 0])\n",
    "flair = ax0.imshow(sample_img[:,:,65], cmap='bone')\n",
    "ax0.set_title(\"FLAIR\", fontsize=18, weight='bold', y=-0.2)\n",
    "fig.colorbar(flair)\n",
    "\n",
    "#  Varying density along a streamline\n",
    "ax1 = fig.add_subplot(gs[0, 1])\n",
    "t1 = ax1.imshow(sample_img2[:,:,65], cmap='bone')\n",
    "ax1.set_title(\"T1\", fontsize=18, weight='bold', y=-0.2)\n",
    "fig.colorbar(t1)\n",
    "\n",
    "#  Varying density along a streamline\n",
    "ax2 = fig.add_subplot(gs[0, 2])\n",
    "t2 = ax2.imshow(sample_img3[:,:,65], cmap='bone')\n",
    "ax2.set_title(\"T2\", fontsize=18, weight='bold', y=-0.2)\n",
    "fig.colorbar(t2)\n",
    "\n",
    "#  Varying density along a streamline\n",
    "ax3 = fig.add_subplot(gs[0, 3])\n",
    "t1ce = ax3.imshow(sample_img4[:,:,65], cmap='bone')\n",
    "ax3.set_title(\"T1 contrast\", fontsize=18, weight='bold', y=-0.2)\n",
    "fig.colorbar(t1ce)\n",
    "\n",
    "#  Varying density along a streamline\n",
    "ax4 = fig.add_subplot(gs[1, 1:3])\n",
    "\n",
    "#ax4.imshow(np.ma.masked_where(mask_WT[:,:,65]== False,  mask_WT[:,:,65]), cmap='summer', alpha=0.6)\n",
    "l1 = ax4.imshow(mask_WT[:,:,65], cmap='summer',)\n",
    "l2 = ax4.imshow(np.ma.masked_where(mask_TC[:,:,65]== False,  mask_TC[:,:,65]), cmap='rainbow', alpha=0.6)\n",
    "l3 = ax4.imshow(np.ma.masked_where(mask_ET[:,:,65] == False, mask_ET[:,:,65]), cmap='winter', alpha=0.6)\n",
    "\n",
    "ax4.set_title(\"\", fontsize=20, weight='bold', y=-0.1)\n",
    "\n",
    "_ = [ax.set_axis_off() for ax in [ax0,ax1,ax2,ax3, ax4]]\n",
    "\n",
    "colors = [im.cmap(im.norm(1)) for im in [l1,l2, l3]]\n",
    "labels = ['Non-Enhancing tumor core', 'Peritumoral Edema ', 'GD-enhancing tumor']\n",
    "patches = [ mpatches.Patch(color=colors[i], label=f\"{labels[i]}\") for i in range(len(labels))]\n",
    "# put those patched as legend-handles into the legend\n",
    "plt.legend(handles=patches, bbox_to_anchor=(1.1, 0.65), loc=2, borderaxespad=0.4,fontsize = 'xx-large',\n",
    "           title='Mask Labels', title_fontsize=18, edgecolor=\"black\",  facecolor='#c5c6c7')\n",
    "\n",
    "plt.suptitle(\"Multimodal Scans -  Data | Manually-segmented mask - Target\", fontsize=20, weight='bold')\n",
    "\n",
    "fig.savefig(\"data_sample.png\", format=\"png\",  pad_inches=0.2, transparent=False, bbox_inches='tight')\n",
    "fig.savefig(\"data_sample.svg\", format=\"svg\",  pad_inches=0.2, transparent=False, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image conversions - 2D , 3D & GIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-06-02T10:56:58.141565Z",
     "iopub.status.busy": "2023-06-02T10:56:58.140905Z",
     "iopub.status.idle": "2023-06-02T10:56:58.178839Z",
     "shell.execute_reply": "2023-06-02T10:56:58.177960Z",
     "shell.execute_reply.started": "2023-06-02T10:56:58.141514Z"
    }
   },
   "outputs": [],
   "source": [
    "class Image3dToGIF3d:\n",
    "    \"\"\"\n",
    "    Displaying 3D images in 3d axes.\n",
    "    Parameters:\n",
    "        img_dim: shape of cube for resizing.\n",
    "        figsize: figure size for plotting in inches.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 img_dim: tuple = (55, 55, 55),\n",
    "                 figsize: tuple = (15, 10),\n",
    "                 binary: bool = False,\n",
    "                 normalizing: bool = True,\n",
    "                ):\n",
    "        \"\"\"Initialization.\"\"\"\n",
    "        self.img_dim = img_dim\n",
    "        print(img_dim)\n",
    "        self.figsize = figsize\n",
    "        self.binary = binary\n",
    "        self.normalizing = normalizing\n",
    "\n",
    "    def _explode(self, data: np.ndarray):\n",
    "        \"\"\"\n",
    "        Takes: array and return an array twice as large in each dimension,\n",
    "        with an extra space between each voxel.\n",
    "        \"\"\"\n",
    "        shape_arr = np.array(data.shape)\n",
    "        size = shape_arr[:3] * 2 - 1\n",
    "        exploded = np.zeros(np.concatenate([size, shape_arr[3:]]),\n",
    "                            dtype=data.dtype)\n",
    "        exploded[::2, ::2, ::2] = data\n",
    "        return exploded\n",
    "\n",
    "    def _expand_coordinates(self, indices: np.ndarray):\n",
    "        x, y, z = indices\n",
    "        x[1::2, :, :] += 1\n",
    "        y[:, 1::2, :] += 1\n",
    "        z[:, :, 1::2] += 1\n",
    "        return x, y, z\n",
    "    \n",
    "    def _normalize(self, arr: np.ndarray):\n",
    "        \"\"\"Normilize image value between 0 and 1.\"\"\"\n",
    "        arr_min = np.min(arr)\n",
    "        return (arr - arr_min) / (np.max(arr) - arr_min)\n",
    "\n",
    "    \n",
    "    def _scale_by(self, arr: np.ndarray, factor: int):\n",
    "        \"\"\"\n",
    "        Scale 3d Image to factor.\n",
    "        Parameters:\n",
    "            arr: 3d image for scalling.\n",
    "            factor: factor for scalling.\n",
    "        \"\"\"\n",
    "        mean = np.mean(arr)\n",
    "        return (arr - mean) * factor + mean\n",
    "    \n",
    "    def get_transformed_data(self, data: np.ndarray):\n",
    "        \"\"\"Data transformation: normalization, scaling, resizing.\"\"\"\n",
    "        if self.binary:\n",
    "            resized_data = resize(data, self.img_dim, preserve_range=True)\n",
    "            return np.clip(resized_data.astype(np.uint8), 0, 1).astype(np.float32)\n",
    "            \n",
    "        norm_data = np.clip(self._normalize(data)-0.1, 0, 1) ** 0.4\n",
    "        scaled_data = np.clip(self._scale_by(norm_data, 2) - 0.1, 0, 1)\n",
    "        resized_data = resize(scaled_data, self.img_dim, preserve_range=True)\n",
    "        \n",
    "        return resized_data\n",
    "    \n",
    "    def plot_cube(self,\n",
    "                  cube,\n",
    "                  title: str = '', \n",
    "                  init_angle: int = 0,\n",
    "                  make_gif: bool = False,\n",
    "                  path_to_save: str = 'filename.gif'\n",
    "                 ):\n",
    "        \"\"\"\n",
    "        Plot 3d data.\n",
    "        Parameters:\n",
    "            cube: 3d data\n",
    "            title: title for figure.\n",
    "            init_angle: angle for image plot (from 0-360).\n",
    "            make_gif: if True create gif from every 5th frames from 3d image plot.\n",
    "            path_to_save: path to save GIF file.\n",
    "            \"\"\"\n",
    "        if self.binary:\n",
    "            facecolors = cm.winter(cube)\n",
    "            print(\"binary\")\n",
    "        else:\n",
    "            if self.normalizing:\n",
    "                cube = self._normalize(cube)\n",
    "            facecolors = cm.gist_stern(cube)\n",
    "            print(\"not binary\")\n",
    "            \n",
    "        facecolors[:,:,:,-1] = cube\n",
    "        facecolors = self._explode(facecolors)\n",
    "\n",
    "        filled = facecolors[:,:,:,-1] != 0\n",
    "        x, y, z = self._expand_coordinates(np.indices(np.array(filled.shape) + 1))\n",
    "\n",
    "        with plt.style.context(\"dark_background\"):\n",
    "\n",
    "            fig = plt.figure(figsize=self.figsize)\n",
    "            ax = fig.gca(projection='3d')\n",
    "\n",
    "            ax.view_init(30, init_angle)\n",
    "            ax.set_xlim(right = self.img_dim[0] * 2)\n",
    "            ax.set_ylim(top = self.img_dim[1] * 2)\n",
    "            ax.set_zlim(top = self.img_dim[2] * 2)\n",
    "            ax.set_title(title, fontsize=18, y=1.05)\n",
    "\n",
    "            ax.voxels(x, y, z, filled, facecolors=facecolors, shade=False)\n",
    "\n",
    "            if make_gif:\n",
    "                images = []\n",
    "                for angle in tqdm(range(0, 360, 5)):\n",
    "                    ax.view_init(30, angle)\n",
    "                    fname = str(angle) + '.png'\n",
    "\n",
    "                    plt.savefig(fname, dpi=120, format='png', bbox_inches='tight')\n",
    "                    images.append(imageio.imread(fname))\n",
    "                    #os.remove(fname)\n",
    "                imageio.mimsave(path_to_save, images)\n",
    "                plt.close()\n",
    "\n",
    "            else:\n",
    "                plt.show()\n",
    "\n",
    "                \n",
    "class ShowResult:\n",
    "  \n",
    "    def mask_preprocessing(self, mask):\n",
    "        \"\"\"\n",
    "        Test.\n",
    "        \"\"\"\n",
    "        # removing all the ones in the tensor --> using cpu --> removing the tensor from its computational graph --> tensor to numpy conversion \n",
    "        mask = mask.squeeze().cpu().detach().numpy()\n",
    "        mask = np.moveaxis(mask, (0, 1, 2, 3), (0, 3, 2, 1))\n",
    "\n",
    "        mask_WT = np.rot90(montage(mask[0]))\n",
    "        mask_TC = np.rot90(montage(mask[1]))\n",
    "        mask_ET = np.rot90(montage(mask[2]))\n",
    "\n",
    "        return mask_WT, mask_TC, mask_ET\n",
    "\n",
    "    def image_preprocessing(self, image):\n",
    "        \"\"\"\n",
    "        Returns image flair as mask for overlaping gt and predictions.\n",
    "        \"\"\"\n",
    "        image = image.squeeze().cpu().detach().numpy()\n",
    "        image = np.moveaxis(image, (0, 1, 2, 3), (0, 3, 2, 1))\n",
    "        flair_img = np.rot90(montage(image[0]))\n",
    "        return flair_img\n",
    "    \n",
    "    def plot(self, image, ground_truth, prediction):\n",
    "        image = self.image_preprocessing(image)\n",
    "        gt_mask_WT, gt_mask_TC, gt_mask_ET = self.mask_preprocessing(ground_truth)\n",
    "        pr_mask_WT, pr_mask_TC, pr_mask_ET = self.mask_preprocessing(prediction)\n",
    "        \n",
    "        fig, axes = plt.subplots(1, 2, figsize = (35, 30))\n",
    "    \n",
    "        [ax.axis(\"off\") for ax in axes]\n",
    "        axes[0].set_title(\"Ground Truth\", fontsize=35, weight='bold')\n",
    "        axes[0].imshow(image, cmap ='bone')\n",
    "        axes[0].imshow(np.ma.masked_where(gt_mask_WT == False, gt_mask_WT),\n",
    "                  cmap='cool_r', alpha=0.6)\n",
    "        axes[0].imshow(np.ma.masked_where(gt_mask_TC == False, gt_mask_TC),\n",
    "                  cmap='autumn_r', alpha=0.6)\n",
    "        axes[0].imshow(np.ma.masked_where(gt_mask_ET == False, gt_mask_ET),\n",
    "                  cmap='autumn', alpha=0.6)\n",
    "\n",
    "        axes[1].set_title(\"Prediction\", fontsize=35, weight='bold')\n",
    "        axes[1].imshow(image, cmap ='bone')\n",
    "        axes[1].imshow(np.ma.masked_where(pr_mask_WT == False, pr_mask_WT),\n",
    "                  cmap='cool_r', alpha=0.6)\n",
    "        axes[1].imshow(np.ma.masked_where(pr_mask_TC == False, pr_mask_TC),\n",
    "                  cmap='autumn_r', alpha=0.6)\n",
    "        axes[1].imshow(np.ma.masked_where(pr_mask_ET == False, pr_mask_ET),\n",
    "                  cmap='autumn', alpha=0.6)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "#show_result = ShowResult()\n",
    "#show_result.plot(data['image'], data['mask'], data['mask'])\n",
    "\n",
    "\n",
    "def merging_two_gif(path1: str, path2: str, name_to_save: str):\n",
    "    \"\"\"\n",
    "    Merging GIFs side by side.\n",
    "    Parameters:\n",
    "        path1: path to gif with ground truth.\n",
    "        path2: path to gif with prediction.\n",
    "        name_to_save: name for saving new GIF.\n",
    "    \"\"\"\n",
    "    #https://stackoverflow.com/questions/51517685/combine-several-gif-horizontally-python\n",
    "    #Create reader object for the gif\n",
    "    gif1 = imageio.get_reader(path1)\n",
    "    gif2 = imageio.get_reader(path2)\n",
    "\n",
    "    #If they don't have the same number of frame take the shorter\n",
    "    number_of_frames = min(gif1.get_length(), gif2.get_length()) \n",
    "\n",
    "    #Create writer object\n",
    "    new_gif = imageio.get_writer(name_to_save)\n",
    "\n",
    "    for frame_number in range(number_of_frames):\n",
    "        img1 = gif1.get_next_data()\n",
    "        img2 = gif2.get_next_data()\n",
    "        #here is the magic\n",
    "        new_image = np.hstack((img1, img2))\n",
    "        new_gif.append_data(new_image)\n",
    "\n",
    "    gif1.close()\n",
    "    gif2.close()    \n",
    "    new_gif.close()\n",
    "    \n",
    "#merging_two_gif('BraTS20_Training_001_flair_3d.gif',\n",
    "#                'BraTS20_Training_001_flair_3d.gif', \n",
    "#                'result.gif')\n",
    "\n",
    "def get_all_csv_file(root: str) -> list:\n",
    "    \"\"\"Extraction all unique ids from file names.\"\"\"\n",
    "    ids = []\n",
    "    for dirname, _, filenames in os.walk(root):\n",
    "        for filename in filenames:\n",
    "            path = os.path.join(dirname, filename)\n",
    "            if path.endswith(\".csv\"):\n",
    "                ids.append(path) \n",
    "    ids = list(set(filter(None, ids)))\n",
    "    print(f\"Extracted {len(ids)} csv files.\")\n",
    "    return ids\n",
    "\n",
    "#csv_paths = get_all_csv_file(\"../input/brats20-dataset-training-validation/BraTS2020_TrainingData\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T10:56:58.180989Z",
     "iopub.status.busy": "2023-06-02T10:56:58.180201Z",
     "iopub.status.idle": "2023-06-02T10:56:58.222022Z",
     "shell.execute_reply": "2023-06-02T10:56:58.221211Z",
     "shell.execute_reply.started": "2023-06-02T10:56:58.180958Z"
    }
   },
   "outputs": [],
   "source": [
    "class GlobalConfig:\n",
    "    root_dir = './dataset'\n",
    "    train_root_dir = './dataset/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData'\n",
    "    test_root_dir = './dataset/BraTS2020_ValidationData/MICCAI_BraTS2020_ValidationData'\n",
    "    path_to_csv = './train_data.csv'\n",
    "    pretrained_model_path = './logs1/last_epoch_model.pth'\n",
    "    train_logs_path = './logs1/train_log.csv'\n",
    "    ae_pretrained_model_path = './logs1/best_model.pth'\n",
    "    tab_data = './logs1/df_with_voxel_stats_and_latent_features.csv'\n",
    "    seed = 55\n",
    "    \n",
    "def seed_everything(seed: int):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "    \n",
    "config = GlobalConfig()\n",
    "seed_everything(config.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T10:56:58.224912Z",
     "iopub.status.busy": "2023-06-02T10:56:58.224275Z",
     "iopub.status.idle": "2023-06-02T10:56:58.229110Z",
     "shell.execute_reply": "2023-06-02T10:56:58.228295Z",
     "shell.execute_reply.started": "2023-06-02T10:56:58.224877Z"
    }
   },
   "outputs": [],
   "source": [
    "# data pre-processing time starts(dpp0)\n",
    "dpp0 = time.time() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T10:56:58.234279Z",
     "iopub.status.busy": "2023-06-02T10:56:58.233465Z",
     "iopub.status.idle": "2023-06-02T10:56:58.272655Z",
     "shell.execute_reply": "2023-06-02T10:56:58.271854Z",
     "shell.execute_reply.started": "2023-06-02T10:56:58.234247Z"
    }
   },
   "outputs": [],
   "source": [
    "survival_info_df = pd.read_csv('./dataset/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/survival_info.csv')\n",
    "name_mapping_df = pd.read_csv('./dataset/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/name_mapping.csv')\n",
    "\n",
    "name_mapping_df.rename({'BraTS_2020_subject_ID': 'Brats20ID'}, axis=1, inplace=True) \n",
    "\n",
    "\n",
    "df = survival_info_df.merge(name_mapping_df, on=\"Brats20ID\", how=\"right\")\n",
    "\n",
    "# renaming & merging into one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T10:56:58.274161Z",
     "iopub.status.busy": "2023-06-02T10:56:58.273868Z",
     "iopub.status.idle": "2023-06-02T10:56:58.303717Z",
     "shell.execute_reply": "2023-06-02T10:56:58.302838Z",
     "shell.execute_reply.started": "2023-06-02T10:56:58.274138Z"
    }
   },
   "outputs": [],
   "source": [
    "paths = []\n",
    "for _, row  in df.iterrows():\n",
    "    \n",
    "    id_ = row['Brats20ID']\n",
    "    phase = id_.split(\"_\")[-2]\n",
    "    if phase == 'Training':\n",
    "        path = os.path.join(config.train_root_dir, id_)\n",
    "    else:\n",
    "        path = os.path.join(config.test_root_dir, id_)\n",
    "    paths.append(path)\n",
    "    \n",
    "df['path'] = paths\n",
    "\n",
    "# config.train_root_dir = \"/data/training\"\n",
    "# id_ = \"BraTS20_Training_001\"\n",
    "# path = os.path.join(config.train_root_dir, id_)\n",
    "# output ==> path = /data/training/BraTS20_Training_001\n",
    "\n",
    "#split data on train, test, split\n",
    "#train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=69, shuffle=True)\n",
    "#train_df, val_df = train_df.reset_index(drop=True), val_df.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T10:56:58.305717Z",
     "iopub.status.busy": "2023-06-02T10:56:58.305330Z",
     "iopub.status.idle": "2023-06-02T10:56:58.317376Z",
     "shell.execute_reply": "2023-06-02T10:56:58.316328Z",
     "shell.execute_reply.started": "2023-06-02T10:56:58.305685Z"
    }
   },
   "outputs": [],
   "source": [
    "# Data cleaning - removing all null age entries\n",
    "train_data = df.loc[df['Age'].notnull()].reset_index(drop=True)\n",
    "\n",
    "# Calculating Age rank for the basis of K - Fold stratification\n",
    "train_data[\"Age_rank\"] =  train_data[\"Age\"] // 10 * 10\n",
    "train_data = train_data.loc[train_data['Brats20ID'] != 'BraTS20_Training_355'].reset_index(drop=True, )\n",
    "\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T10:56:58.319517Z",
     "iopub.status.busy": "2023-06-02T10:56:58.319187Z",
     "iopub.status.idle": "2023-06-02T10:56:58.323435Z",
     "shell.execute_reply": "2023-06-02T10:56:58.322598Z",
     "shell.execute_reply.started": "2023-06-02T10:56:58.319487Z"
    }
   },
   "outputs": [],
   "source": [
    "# stratified k-fold ( skf ) time starts \n",
    "skf0 = time.time() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T10:56:58.325618Z",
     "iopub.status.busy": "2023-06-02T10:56:58.324953Z",
     "iopub.status.idle": "2023-06-02T10:56:58.342798Z",
     "shell.execute_reply": "2023-06-02T10:56:58.341962Z",
     "shell.execute_reply.started": "2023-06-02T10:56:58.325588Z"
    }
   },
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(\n",
    "    n_splits=7, random_state=config.seed, shuffle=True\n",
    ")\n",
    "\n",
    "# enumeratng all entries for defining the fold number \n",
    "# assigning the fold number in increment order \n",
    "for i, (train_index, val_index) in enumerate(\n",
    "        skf.split(train_data, train_data[\"Age_rank\"])\n",
    "        ):\n",
    "        train_data.loc[val_index, \"fold\"] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T10:56:58.345874Z",
     "iopub.status.busy": "2023-06-02T10:56:58.345628Z",
     "iopub.status.idle": "2023-06-02T10:56:58.352771Z",
     "shell.execute_reply": "2023-06-02T10:56:58.351695Z",
     "shell.execute_reply.started": "2023-06-02T10:56:58.345852Z"
    }
   },
   "outputs": [],
   "source": [
    "# total stratification time(skft) \n",
    "skf1 = time.time()\n",
    "skft = skf1 - skf0 \n",
    "print(\"Stratification time : \",skft ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T10:56:58.356158Z",
     "iopub.status.busy": "2023-06-02T10:56:58.354306Z",
     "iopub.status.idle": "2023-06-02T10:56:58.366414Z",
     "shell.execute_reply": "2023-06-02T10:56:58.365280Z",
     "shell.execute_reply.started": "2023-06-02T10:56:58.356131Z"
    }
   },
   "outputs": [],
   "source": [
    "# splitting of the data wasn't done for train , test &  validation data \n",
    "train_df = train_data.loc[train_data['fold'] != 0].reset_index(drop=True)\n",
    "val_df = train_data.loc[train_data['fold'] == 0].reset_index(drop=True)\n",
    "\n",
    "# selecting the rows where the AGE col. is null --> test_df \n",
    "test_df = df.loc[~df['Age'].notnull()].reset_index(drop=True)\n",
    "print(\"train_df ->\", train_df.shape, \"val_df ->\", val_df.shape, \"test_df ->\", test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T10:56:58.369372Z",
     "iopub.status.busy": "2023-06-02T10:56:58.368496Z",
     "iopub.status.idle": "2023-06-02T10:56:58.374509Z",
     "shell.execute_reply": "2023-06-02T10:56:58.373593Z",
     "shell.execute_reply.started": "2023-06-02T10:56:58.369348Z"
    }
   },
   "outputs": [],
   "source": [
    "# total data pre-processing time(dppt)\n",
    "dpp1 = time.time() \n",
    "dppt = dpp1 - dpp0 - skft\n",
    "print(\"Data preprocessing time : \", dppt  ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T10:56:58.376759Z",
     "iopub.status.busy": "2023-06-02T10:56:58.376028Z",
     "iopub.status.idle": "2023-06-02T10:56:58.396775Z",
     "shell.execute_reply": "2023-06-02T10:56:58.395967Z",
     "shell.execute_reply.started": "2023-06-02T10:56:58.376729Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data.to_csv(\"train_data.csv\", index=False)\n",
    "test_df.to_csv(\"test_df.csv\", index=False)\n",
    "train_df.to_csv(\"train_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset dataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T10:56:58.398953Z",
     "iopub.status.busy": "2023-06-02T10:56:58.398209Z",
     "iopub.status.idle": "2023-06-02T10:56:58.417846Z",
     "shell.execute_reply": "2023-06-02T10:56:58.416995Z",
     "shell.execute_reply.started": "2023-06-02T10:56:58.398920Z"
    }
   },
   "outputs": [],
   "source": [
    "class BratsDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, phase: str=\"test\", is_resize: bool=False):\n",
    "        self.df = df\n",
    "        self.phase = phase\n",
    "        self.augmentations = get_augmentations(phase)\n",
    "        self.data_types = ['_flair.nii', '_t1.nii', '_t1ce.nii', '_t2.nii']\n",
    "        self.is_resize = is_resize\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0] \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # at a specified index ( idx ) select the value under 'Brats20ID' & asssign it to id_ \n",
    "        id_ = self.df.loc[idx, 'Brats20ID']\n",
    "        \n",
    "        # As we've got the id_ , now find the path of the entry by asserting the Brats20ID to id_ \n",
    "        root_path = self.df.loc[self.df['Brats20ID'] == id_]['path'].values[0]\n",
    "        \n",
    "        # load all modalities\n",
    "        images = []\n",
    "        \n",
    "        for data_type in self.data_types:\n",
    "            # here data_type is appended to the root path, as it only contains the name without the datatype such as .nii etc\n",
    "            img_path = os.path.join(root_path, id_ + data_type) \n",
    "            img = self.load_img(img_path)#.transpose(2, 0, 1)\n",
    "            \n",
    "            if self.is_resize:\n",
    "                img = self.resize(img)\n",
    "    \n",
    "            img = self.normalize(img)\n",
    "            images.append(img)\n",
    "            \n",
    "        # stacking all the t1 , t1ce , t2 , t2 flair files of a single ID in a stack \n",
    "        img = np.stack(images)\n",
    "        img = np.moveaxis(img, (0, 1, 2, 3), (0, 3, 2, 1))\n",
    "        \n",
    "        if self.phase != \"test\":\n",
    "            mask_path =  os.path.join(root_path, id_ + \"_seg.nii\")\n",
    "            mask = self.load_img(mask_path)\n",
    "            \n",
    "            if self.is_resize:\n",
    "                mask = self.resize(mask)\n",
    "                # mask --> conversion to uint8 --> normalization / clipping ( 0 to 1 ) --> conversion to float32 \n",
    "                mask = np.clip(mask.astype(np.uint8), 0, 1).astype(np.float32)\n",
    "                # again clipping ( 0 to 1 ) \n",
    "                mask = np.clip(mask, 0, 1)\n",
    "            \n",
    "            # setting the mask labels 1 , 2 , 4 for the mask file ( _seg.ii ) \n",
    "            mask = self.preprocess_mask_labels(mask)\n",
    "    \n",
    "            augmented = self.augmentations(image=img.astype(np.float32), \n",
    "                                           mask=mask.astype(np.float32))\n",
    "            # Several augmentations / transformations like flipping, rotating, padding will be applied to both the images \n",
    "            img = augmented['image']\n",
    "            mask = augmented['mask']\n",
    "    \n",
    "        \n",
    "            return {\n",
    "                \"Id\": id_,\n",
    "                \"image\": img,\n",
    "                \"mask\": mask,\n",
    "            }\n",
    "        \n",
    "        return {\n",
    "            \"Id\": id_,\n",
    "            \"image\": img,\n",
    "        }\n",
    "    \n",
    "    def load_img(self, file_path):\n",
    "        data = nib.load(file_path)\n",
    "        data = np.asarray(data.dataobj)\n",
    "        return data\n",
    "    \n",
    "    def normalize(self, data: np.ndarray):\n",
    "        data_min = np.min(data)\n",
    "        # normalization = (each element - min element) / ( max - min ) \n",
    "        return (data - data_min) / (np.max(data) - data_min)\n",
    "    \n",
    "    def resize(self, data: np.ndarray):\n",
    "        data = resize(data, (78, 120, 120), preserve_range=True)\n",
    "        return data\n",
    "    \n",
    "    def preprocess_mask_labels(self, mask: np.ndarray):\n",
    "\n",
    "        # whole tumour\n",
    "        mask_WT = mask.copy()\n",
    "        mask_WT[mask_WT == 1] = 1\n",
    "        mask_WT[mask_WT == 2] = 1\n",
    "        mask_WT[mask_WT == 4] = 1\n",
    "        # include all tumours \n",
    "\n",
    "        # NCR / NET - LABEL 1\n",
    "        mask_TC = mask.copy()\n",
    "        mask_TC[mask_TC == 1] = 1\n",
    "        mask_TC[mask_TC == 2] = 0\n",
    "        mask_TC[mask_TC == 4] = 1\n",
    "        # exclude 2 / 4 labelled tumour \n",
    "        \n",
    "        # ET - LABEL 4 \n",
    "        mask_ET = mask.copy()\n",
    "        mask_ET[mask_ET == 1] = 0\n",
    "        mask_ET[mask_ET == 2] = 0\n",
    "        mask_ET[mask_ET == 4] = 1\n",
    "        # exclude 2 / 1 labelled tumour \n",
    "        \n",
    "        # ED - LABEL 2\n",
    "        # mask_ED = mask.copy()\n",
    "        # mask_ED[mask_ED == 1] = 0\n",
    "        # mask_ED[mask_ED == 2] = 1\n",
    "        # mask_ED[mask_ED == 4] = 0\n",
    "\n",
    "\n",
    "        # mask = np.stack([mask_WT, mask_TC, mask_ET, mask_ED])\n",
    "        mask = np.stack([mask_WT, mask_TC, mask_ET])\n",
    "        mask = np.moveaxis(mask, (0, 1, 2, 3), (0, 3, 2, 1))\n",
    "\n",
    "        return mask        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T10:56:58.419660Z",
     "iopub.status.busy": "2023-06-02T10:56:58.419300Z",
     "iopub.status.idle": "2023-06-02T10:56:58.431690Z",
     "shell.execute_reply": "2023-06-02T10:56:58.430806Z",
     "shell.execute_reply.started": "2023-06-02T10:56:58.419630Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_augmentations(phase):\n",
    "    list_transforms = []\n",
    "    \n",
    "    # Does data augmentations & tranformation required for IMAGES & MASKS \n",
    "    # they include cropping, padding, flipping , rotating \n",
    "    list_trfms = Compose(list_transforms)\n",
    "    return list_trfms\n",
    "\n",
    "\n",
    "def get_dataloader(\n",
    "    dataset: torch.utils.data.Dataset,\n",
    "    path_to_csv: str,\n",
    "    phase: str,\n",
    "    fold: int = 0,\n",
    "    batch_size: int = 1,\n",
    "    num_workers: int = 4 ):\n",
    "    \n",
    "    '''Returns: dataloader for the model training'''\n",
    "    df = pd.read_csv(path_to_csv)\n",
    "        \n",
    "    # selecting train_df to be all the entries EXCEPT the mentioned fold while calling dataloader \n",
    "    train_df = df.loc[df['fold'] != fold].reset_index(drop=True)\n",
    "    \n",
    "    # selection a particluar fold while calling the get_dataloader function \n",
    "    val_df = df.loc[df['fold'] == fold].reset_index(drop=True)\n",
    "#     test_df = df.loc[~df['Age'].notnull()].reset_index(drop=True)\n",
    "#     print(len(train_df) , len(val_df), len(test_df))\n",
    "\n",
    "    \n",
    "    # read csv --> train & validation df splitting --> assigning train_df / val_df to df based on phase --> returning dataloader \n",
    "    # how does val_df / train_df got converted to ( id , image tensor , mask tensor )\n",
    "    \n",
    "    if phase == \"train\" : \n",
    "        df = train_df \n",
    "    elif phase == \"valid\" :\n",
    "        df = val_df\n",
    "#     else:\n",
    "#         df = test_df\n",
    "    dataset = dataset(df, phase)\n",
    "    \"\"\"\n",
    "    DataLoader iteratively goes through every id in the df & gets all the individual tuples for individual ids & appends all of them \n",
    "    like this : \n",
    "    { id : ['BraTS20_Training_235'] ,\n",
    "      image : [] , \n",
    "      tensor : [] , \n",
    "    } \n",
    "    { id : ['BraTS20_Training_236'] ,\n",
    "      image : [] , \n",
    "      tensor : [] , \n",
    "    } \n",
    "    { id : ['BraTS20_Training_237'] ,\n",
    "      image : [] , \n",
    "      tensor : [] , \n",
    "    } \n",
    "    \"\"\"\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        shuffle=True,   \n",
    "    )\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T10:56:58.433627Z",
     "iopub.status.busy": "2023-06-02T10:56:58.433007Z",
     "iopub.status.idle": "2023-06-02T10:56:58.451525Z",
     "shell.execute_reply": "2023-06-02T10:56:58.450455Z",
     "shell.execute_reply.started": "2023-06-02T10:56:58.433597Z"
    }
   },
   "outputs": [],
   "source": [
    "dataloader = get_dataloader(dataset=BratsDataset, path_to_csv='train_data.csv', phase='valid', fold=0)\n",
    "len(dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T10:56:58.453577Z",
     "iopub.status.busy": "2023-06-02T10:56:58.452965Z",
     "iopub.status.idle": "2023-06-02T10:57:08.861709Z",
     "shell.execute_reply": "2023-06-02T10:57:08.860564Z",
     "shell.execute_reply.started": "2023-06-02T10:56:58.453545Z"
    }
   },
   "outputs": [],
   "source": [
    "data = next(iter(dataloader))\n",
    "data['Id'], data['image'].shape, data['mask'].shape\n",
    "\n",
    "# batch size , channels , spatial dimensions\n",
    "# no.of images in a batch : channels : t1 , t2 , flair , weighted : dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T10:57:08.864841Z",
     "iopub.status.busy": "2023-06-02T10:57:08.863351Z",
     "iopub.status.idle": "2023-06-02T10:57:08.870923Z",
     "shell.execute_reply": "2023-06-02T10:57:08.869862Z",
     "shell.execute_reply.started": "2023-06-02T10:57:08.864790Z"
    }
   },
   "outputs": [],
   "source": [
    "print(data['image'].shape)\n",
    "print(data['mask'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T10:57:08.873066Z",
     "iopub.status.busy": "2023-06-02T10:57:08.872471Z",
     "iopub.status.idle": "2023-06-02T10:57:13.095644Z",
     "shell.execute_reply": "2023-06-02T10:57:13.094838Z",
     "shell.execute_reply.started": "2023-06-02T10:57:08.873034Z"
    }
   },
   "outputs": [],
   "source": [
    "# Printing all the images & masks of \"FOLD 0\" --> 34 batches \n",
    "# 34 BATCHES of images & masks each batch containing 4 types of files t1 , t2 , t1ce , flair \n",
    "\n",
    "img_tensor = data['image'].squeeze()[0].cpu().detach().numpy() \n",
    "mask_tensor = data['mask'].squeeze()[0].squeeze().cpu().detach().numpy()\n",
    "\n",
    "print(\"Num uniq Image values :\", len(np.unique(img_tensor, return_counts=True)[0]))\n",
    "print(\"Min/Max Image values:\", img_tensor.min(), img_tensor.max())\n",
    "print(\"Num uniq Mask values:\", np.unique(mask_tensor, return_counts=True))\n",
    "\n",
    "image = np.rot90(montage(img_tensor))\n",
    "mask = np.rot90(montage(mask_tensor)) \n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize = (20, 20))\n",
    "ax.imshow(image, cmap ='bone')\n",
    "ax.imshow(np.ma.masked_where(mask == False, mask),\n",
    "           cmap='cool', alpha=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T10:57:13.097824Z",
     "iopub.status.busy": "2023-06-02T10:57:13.096842Z",
     "iopub.status.idle": "2023-06-02T10:57:13.146504Z",
     "shell.execute_reply": "2023-06-02T10:57:13.145572Z",
     "shell.execute_reply.started": "2023-06-02T10:57:13.097791Z"
    }
   },
   "outputs": [],
   "source": [
    "img_tensor.shape \n",
    "mask_tensor.shape\n",
    "\n",
    "image = np.rot90(montage(img_tensor))\n",
    "mask = np.rot90(montage(mask_tensor)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics and Loss metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T10:57:13.148668Z",
     "iopub.status.busy": "2023-06-02T10:57:13.148286Z",
     "iopub.status.idle": "2023-06-02T10:57:13.180939Z",
     "shell.execute_reply": "2023-06-02T10:57:13.180034Z",
     "shell.execute_reply.started": "2023-06-02T10:57:13.148634Z"
    }
   },
   "outputs": [],
   "source": [
    "def dice_coef_metric(probabilities: torch.Tensor,\n",
    "                     truth: torch.Tensor, \n",
    "                     treshold: float = 0.5,\n",
    "                     eps: float = 1e-9) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculate Dice score for data batch.\n",
    "    Params:\n",
    "        probobilities: model outputs after activation function.\n",
    "        truth: truth values.\n",
    "        threshold: threshold for probabilities.\n",
    "        eps: additive to refine the estimate.\n",
    "        Returns: dice score aka f1.\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    num = probabilities.shape[0] \n",
    "    predictions = (probabilities >= treshold).float()\n",
    "    assert(predictions.shape == truth.shape)\n",
    "    for i in range(num):\n",
    "        prediction = predictions[i]\n",
    "        truth_ = truth[i]\n",
    "        intersection = 2.0 * (truth_ * prediction).sum()\n",
    "        union = truth_.sum() + prediction.sum()\n",
    "        if truth_.sum() == 0 and prediction.sum() == 0:\n",
    "            scores.append(1.0)\n",
    "        else:\n",
    "            scores.append((intersection + eps) / union)\n",
    "    return np.mean(scores)\n",
    "\n",
    "\n",
    "def jaccard_coef_metric(probabilities: torch.Tensor,\n",
    "               truth: torch.Tensor,\n",
    "               treshold: float = 0.5,\n",
    "               eps: float = 1e-9) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculate Jaccard index for data batch.\n",
    "    Params:\n",
    "        probobilities: model outputs after activation function.\n",
    "        truth: truth values.\n",
    "        threshold: threshold for probabilities.\n",
    "        eps: additive to refine the estimate.\n",
    "        Returns: jaccard score aka iou.\"\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    num = probabilities.shape[0]\n",
    "    predictions = (probabilities >= treshold).float()\n",
    "    assert(predictions.shape == truth.shape)\n",
    "\n",
    "    for i in range(num):\n",
    "        prediction = predictions[i]\n",
    "        truth_ = truth[i]\n",
    "        intersection = (prediction * truth_).sum()\n",
    "        union = (prediction.sum() + truth_.sum()) - intersection + eps\n",
    "        if truth_.sum() == 0 and prediction.sum() == 0:\n",
    "            scores.append(1.0)\n",
    "        else:\n",
    "            scores.append((intersection + eps) / union)\n",
    "    return np.mean(scores)\n",
    "\n",
    "\n",
    "class Meter:\n",
    "    '''factory for storing and updating iou and dice scores.'''\n",
    "    def __init__(self, treshold: float = 0.5):\n",
    "        self.threshold: float = treshold\n",
    "        self.dice_scores: list = []\n",
    "        self.iou_scores: list = []\n",
    "    \n",
    "    def update(self, logits: torch.Tensor, targets: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Takes: logits from output model and targets,\n",
    "        calculates dice and iou scores, and stores them in lists.\n",
    "        calculates using the above declare functions \n",
    "        \"\"\"\n",
    "        probs = torch.sigmoid(logits)\n",
    "        dice = dice_coef_metric(probs, targets, self.threshold)\n",
    "        iou = jaccard_coef_metric(probs, targets, self.threshold)\n",
    "        \n",
    "        # appending to the respective lists \n",
    "        self.dice_scores.append(dice)\n",
    "        self.iou_scores.append(iou)\n",
    "    \n",
    "    def get_metrics(self) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Returns: the average of the accumulated dice and iou scores.\n",
    "        \"\"\"\n",
    "        dice = np.mean(self.dice_scores)\n",
    "        iou = np.mean(self.iou_scores)\n",
    "        return dice, iou\n",
    "\n",
    "\n",
    "class DiceLoss(nn.Module):\n",
    "    \"\"\"Calculate dice loss.\"\"\"\n",
    "    def __init__(self, eps: float = 1e-9):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.eps = eps\n",
    "        \n",
    "    def forward(self,\n",
    "                logits: torch.Tensor,\n",
    "                targets: torch.Tensor) -> torch.Tensor:\n",
    "        \n",
    "        num = targets.size(0)\n",
    "        probability = torch.sigmoid(logits)\n",
    "        probability = probability.view(num, -1)\n",
    "        targets = targets.view(num, -1)\n",
    "        assert(probability.shape == targets.shape)\n",
    "        \n",
    "        intersection = 2.0 * (probability * targets).sum()\n",
    "        union = probability.sum() + targets.sum()\n",
    "        dice_score = (intersection + self.eps) / union\n",
    "        #print(\"intersection\", intersection, union, dice_score)\n",
    "        return 1.0 - dice_score\n",
    "        \n",
    "        \n",
    "class BCEDiceLoss(nn.Module):\n",
    "    \"\"\"Compute objective loss: BCE loss + DICE loss.\"\"\"\n",
    "    def __init__(self):\n",
    "        super(BCEDiceLoss, self).__init__()\n",
    "        self.bce = nn.BCEWithLogitsLoss()\n",
    "        self.dice = DiceLoss()\n",
    "        \n",
    "    def forward(self, \n",
    "                logits: torch.Tensor,\n",
    "                targets: torch.Tensor) -> torch.Tensor:\n",
    "        \n",
    "        # logits are the images \n",
    "        # target are the masks \n",
    "        assert(logits.shape == targets.shape)\n",
    "        dice_loss = self.dice(logits, targets)\n",
    "        bce_loss = self.bce(logits, targets)\n",
    "        \n",
    "        # binary cross entropy loss & dice loss \n",
    "        return bce_loss + dice_loss\n",
    "    \n",
    "# helper functions for testing.  \n",
    "def dice_coef_metric_per_classes(probabilities: np.ndarray,\n",
    "                                    truth: np.ndarray,\n",
    "                                    treshold: float = 0.5,\n",
    "                                    eps: float = 1e-9,\n",
    "                                    classes: list = ['WT', 'TC', 'ET']) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculate Dice score for data batch and for each class i.e. 'WT', 'TC', 'ET'\n",
    "    Params:\n",
    "        probobilities: model outputs after activation function.\n",
    "        truth: model targets.\n",
    "        threshold: threshold for probabilities.\n",
    "        eps: additive to refine the estimate.\n",
    "        classes: list with name classes.\n",
    "        Returns: dict with dice scores for each class.\n",
    "    \"\"\"\n",
    "    scores = {key: list() for key in classes}\n",
    "    num = probabilities.shape[0]\n",
    "    num_classes = probabilities.shape[1]\n",
    "    predictions = (probabilities >= treshold).astype(np.float32)\n",
    "    assert(predictions.shape == truth.shape)\n",
    "\n",
    "    for i in range(num):\n",
    "        for class_ in range(num_classes):\n",
    "            prediction = predictions[i][class_]\n",
    "            truth_ = truth[i][class_]\n",
    "            intersection = 2.0 * (truth_ * prediction).sum()\n",
    "            union = truth_.sum() + prediction.sum()\n",
    "            if truth_.sum() == 0 and prediction.sum() == 0:\n",
    "                 scores[classes[class_]].append(1.0)\n",
    "            else:\n",
    "                scores[classes[class_]].append((intersection + eps) / union)\n",
    "                \n",
    "    return scores\n",
    "\n",
    "\n",
    "def jaccard_coef_metric_per_classes(probabilities: np.ndarray, # output of the model in an array format \n",
    "               truth: np.ndarray,# masks  \n",
    "               treshold: float = 0.5, # threshold to whether segment / not \n",
    "               eps: float = 1e-9, # smooth \n",
    "               classes: list = ['WT', 'TC', 'ET']) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculate Jaccard index for data batch and for each class.\n",
    "    Params:\n",
    "        probobilities: model outputs after activation function.\n",
    "        truth: model targets.\n",
    "        threshold: threshold for probabilities.\n",
    "        eps: additive to refine the estimate.\n",
    "        classes: list with name classes.\n",
    "        Returns: dict with jaccard scores for each class.\"\n",
    "    \"\"\"\n",
    "    scores = {key: list() for key in classes}\n",
    "    # storing all the jaccard coefficients in a list \n",
    "    \n",
    "    num = probabilities.shape[0]\n",
    "    \n",
    "    num_classes = probabilities.shape[1]\n",
    "    \n",
    "    # segmenting if prob > threshold .i.e. setting to float32 \n",
    "    predictions = (probabilities >= treshold).astype(np.float32)\n",
    "    \n",
    "    assert(predictions.shape == truth.shape)\n",
    "\n",
    "    for i in range(num):\n",
    "        for class_ in range(num_classes):\n",
    "            prediction = predictions[i][class_]\n",
    "            truth_ = truth[i][class_]\n",
    "            intersection = (prediction * truth_).sum()\n",
    "            union = (prediction.sum() + truth_.sum()) - intersection + eps\n",
    "            if truth_.sum() == 0 and prediction.sum() == 0:\n",
    "                 scores[classes[class_]].append(1.0)\n",
    "            else:\n",
    "                scores[classes[class_]].append((intersection + eps) / union)\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3DAttentionrResUnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T10:57:13.183146Z",
     "iopub.status.busy": "2023-06-02T10:57:13.182598Z",
     "iopub.status.idle": "2023-06-02T10:57:13.205098Z",
     "shell.execute_reply": "2023-06-02T10:57:13.204225Z",
     "shell.execute_reply.started": "2023-06-02T10:57:13.183113Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(Conv3D -> BN -> ReLU) * 2 with residual connection\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, num_groups=8):\n",
    "        super().__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.GroupNorm(num_groups=num_groups, num_channels=out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(out_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.GroupNorm(num_groups=num_groups, num_channels=out_channels),\n",
    "        )\n",
    "        self.residual = nn.Conv3d(in_channels, out_channels, kernel_size=1)  # Residual connection\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = self.residual(x)\n",
    "        out = self.double_conv(x)\n",
    "        out += residual  # Add the residual connection\n",
    "        out = F.relu(out, inplace=True)\n",
    "        return out\n",
    "\n",
    "class AttentionBlock(nn.Module):\n",
    "    \"\"\"Attention Block for Attention ResUNet3D\"\"\"\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "        self.downsample = nn.Conv3d(in_channels, 1, kernel_size=1)  # Reduce channels to 1 for attention\n",
    "\n",
    "    def forward(self, x):\n",
    "        weights = torch.sigmoid(self.downsample(x))  # Calculate attention weights\n",
    "        return x * weights  # Apply attention to the input feature map\n",
    "\n",
    "class Down(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.MaxPool3d(2, 2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "class Up(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, trilinear=True):\n",
    "        super().__init__()\n",
    "\n",
    "        if trilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='trilinear', align_corners=True)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose3d(in_channels // 2, in_channels // 2, kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "\n",
    "        diffZ = x2.size()[2] - x1.size()[2]\n",
    "        diffY = x2.size()[3] - x1.size()[3]\n",
    "        diffX = x2.size()[4] - x1.size()[4]\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2, diffY // 2, diffY - diffY // 2, diffZ // 2, diffZ - diffZ // 2])\n",
    "\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "class Out(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class AttentionUNet3D(nn.Module):\n",
    "    def __init__(self, in_channels, n_classes, n_channels):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.n_channels = n_channels\n",
    "\n",
    "        self.conv = DoubleConv(in_channels, n_channels)\n",
    "        self.enc1 = Down(n_channels, 2 * n_channels)\n",
    "        self.enc2 = Down(2 * n_channels, 4 * n_channels)\n",
    "        self.enc3 = Down(4 * n_channels, 8 * n_channels)\n",
    "        self.enc4 = Down(8 * n_channels, 8 * n_channels)\n",
    "\n",
    "        self.attention1 = AttentionBlock(2 * n_channels)\n",
    "        self.attention2 = AttentionBlock(4 * n_channels)\n",
    "        self.attention3 = AttentionBlock(8 * n_channels)\n",
    "\n",
    "        self.dec1 = Up(16 * n_channels, 4 * n_channels)\n",
    "        self.dec2 = Up(8 * n_channels, 2 * n_channels)\n",
    "        self.dec3 = Up(4 * n_channels, n_channels)\n",
    "        self.dec4 = Up(2 * n_channels, n_channels)\n",
    "        self.out = Out(n_channels, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.conv(x)\n",
    "        x2 = self.enc1(x1)\n",
    "        x3 = self.enc2(x2)\n",
    "        x4 = self.enc3(x3)\n",
    "        x5 = self.enc4(x4)\n",
    "\n",
    "        x5 = self.attention3(x5)\n",
    "\n",
    "        mask = self.dec1(x5, x4)\n",
    "        mask = self.attention2(mask)\n",
    "\n",
    "        mask = self.dec2(mask, x3)\n",
    "        mask = self.attention1(mask)\n",
    "\n",
    "        mask = self.dec3(mask, x2)\n",
    "        mask = self.dec4(mask, x1)\n",
    "        mask = self.out(mask)\n",
    "\n",
    "        return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T10:57:13.216562Z",
     "iopub.status.busy": "2023-06-02T10:57:13.215898Z",
     "iopub.status.idle": "2023-06-02T10:57:13.245527Z",
     "shell.execute_reply": "2023-06-02T10:57:13.244615Z",
     "shell.execute_reply.started": "2023-06-02T10:57:13.216513Z"
    }
   },
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    \"\"\"\n",
    "    Factory for training process.\n",
    "    Args:\n",
    "        display_plot: if True - plot train history after each epoch.\n",
    "        net: neural network for mask prediction.\n",
    "        criterion: factory for calculating objective loss. i.e. bce loss + dice loss / others\n",
    "        optimizer: optimizer for weights updating. i.e. Adam\n",
    "        phases: list with train and validation phases.\n",
    "        dataloaders: dict with data loaders for train and val phases. i.e. DataLoader / dataloader\n",
    "        path_to_csv: path to csv file.\n",
    "        meter: factory for storing and updating metrics. -> return the jaccard coeff / dice loss\n",
    "        batch_size: data batch size for one step weights updating.\n",
    "        num_epochs: num weights updation for all data.\n",
    "        accumulation_steps: the number of steps after which the optimization step can be taken\n",
    "                    (https://www.kaggle.com/c/understanding_cloud_organization/discussion/105614).\n",
    "        lr: learning rate for optimizer.\n",
    "        scheduler: scheduler for control learning rate.\n",
    "        losses: dict for storing lists with losses for each phase.\n",
    "        jaccard_scores: dict for storing lists with jaccard scores for each phase.\n",
    "        dice_scores: dict for storing lists with dice scores for each phase.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 net: nn.Module,\n",
    "                 dataset: torch.utils.data.Dataset,\n",
    "                 criterion: nn.Module,\n",
    "                 lr: float,\n",
    "                 accumulation_steps: int,\n",
    "                 batch_size: int,\n",
    "                 fold: int,\n",
    "                 num_epochs: int,\n",
    "                 path_to_csv: str,\n",
    "                 display_plot: bool = True,\n",
    "                ):\n",
    "\n",
    "        \"\"\"Initialization.\"\"\"\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        print(\"Device:\", self.device)\n",
    "        self.display_plot = display_plot\n",
    "        self.net = net\n",
    "        self.net = self.net.to(self.device)\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = Adam(self.net.parameters(), lr=lr)\n",
    "        self.scheduler = ReduceLROnPlateau(self.optimizer, mode=\"min\", patience=2, verbose=True)\n",
    "        self.accumulation_steps = accumulation_steps // batch_size\n",
    "        self.phases = [\"train\", \"val\"]\n",
    "        self.num_epochs = num_epochs\n",
    "\n",
    "        self.dataloaders = {\n",
    "            phase: get_dataloader(\n",
    "                dataset=dataset,\n",
    "                path_to_csv=path_to_csv,\n",
    "                phase=phase,\n",
    "                fold=fold,\n",
    "                batch_size=batch_size,\n",
    "                num_workers=4\n",
    "            )\n",
    "            for phase in self.phases\n",
    "        }\n",
    "        self.best_loss = float(\"inf\")\n",
    "\n",
    "        # calculating the list of losses for both train & validation phases\n",
    "        self.losses = {phase: [] for phase in self.phases}\n",
    "\n",
    "        # calculating the dice scores for both train & validation phases\n",
    "        self.dice_scores = {phase: [] for phase in self.phases}\n",
    "\n",
    "        # calculating the jaccard scores for both train & validation phases\n",
    "        self.jaccard_scores = {phase: [] for phase in self.phases}\n",
    "\n",
    "    def _compute_loss_and_outputs(self,\n",
    "                                  images: torch.Tensor,\n",
    "                                  targets: torch.Tensor):\n",
    "        images = images.to(self.device)\n",
    "        targets = targets.to(self.device)\n",
    "\n",
    "        # making images predictions symmetric using logits\n",
    "        logits = self.net(images)\n",
    "\n",
    "        # calculating the loss bce loss / dice loss / jaccard loss / combined loss\n",
    "        # as defined calculating the mean square error loss\n",
    "        loss = self.criterion(logits, targets)\n",
    "        return loss, logits\n",
    "\n",
    "    def _do_epoch(self, epoch: int, phase: str):\n",
    "        print(f\"{phase} epoch: {epoch} | time: {time.strftime('%H:%M:%S')}\")\n",
    "\n",
    "        self.net.train() if phase == \"train\" else self.net.eval()\n",
    "        meter = Meter()\n",
    "        dataloader = self.dataloaders[phase]\n",
    "        total_batches = len(dataloader)\n",
    "        running_loss = 0.0\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        loop = tqdm(enumerate(dataloader), total=total_batches)\n",
    "        for itr, data_batch in loop:\n",
    "            images, targets = data_batch['image'], data_batch['mask']\n",
    "            loss, logits = self._compute_loss_and_outputs(images, targets)\n",
    "            loss = loss / self.accumulation_steps\n",
    "\n",
    "            if phase == \"train\":\n",
    "                loss.backward()\n",
    "\n",
    "                if (itr + 1) % self.accumulation_steps == 0:\n",
    "                    self.optimizer.step()\n",
    "                    self.optimizer.zero_grad()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            meter.update(logits.detach().cpu(), targets.detach().cpu())\n",
    "\n",
    "            # Update the progress bar\n",
    "            loop.set_postfix(loss=running_loss / (itr + 1))\n",
    "\n",
    "        epoch_loss = (running_loss * self.accumulation_steps) / total_batches\n",
    "        epoch_dice, epoch_iou = meter.get_metrics()\n",
    "\n",
    "        self.losses[phase].append(epoch_loss)\n",
    "        self.dice_scores[phase].append(epoch_dice)\n",
    "        self.jaccard_scores[phase].append(epoch_iou)\n",
    "\n",
    "        return epoch_loss\n",
    "\n",
    "    def run(self, early_stopping=False, patience=5, checkpoint_path=\"./checkpoints\"):\n",
    "        best_val_score = 0\n",
    "        early_stopping_counter = 0\n",
    "\n",
    "        for epoch in range(1, self.num_epochs+1):\n",
    "            self._do_epoch(epoch, \"train\")\n",
    "            with torch.no_grad():\n",
    "                val_loss = self._do_epoch(epoch, \"val\")\n",
    "                val_dice_score = self.dice_scores[\"val\"][-1]\n",
    "                print(f\"BCEDiceLoss for epoch {epoch} is: \", val_loss)\n",
    "                print(f\"Validation dice score for epoch {epoch} is: \", val_dice_score)\n",
    "                self.scheduler.step(val_loss)\n",
    "\n",
    "            if self.display_plot:\n",
    "                self._plot_train_history()\n",
    "\n",
    "            if val_dice_score > best_val_score:\n",
    "                best_val_score = val_dice_score\n",
    "                early_stopping_counter = 0\n",
    "                torch.save(self.net.state_dict(), os.path.join(checkpoint_path, \"best_model.pth\"))\n",
    "            else:\n",
    "                early_stopping_counter += 1\n",
    "                if early_stopping and early_stopping_counter >= patience:\n",
    "                    print(f\"Early stopping after {epoch} epochs.\")\n",
    "                    break\n",
    "\n",
    "            print()\n",
    "\n",
    "        self._save_train_history()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    def _plot_train_history(self):\n",
    "        data = [self.losses, self.dice_scores, self.jaccard_scores]\n",
    "        colors = ['deepskyblue', \"crimson\"]\n",
    "        labels = [\n",
    "            f\"\"\"\n",
    "            train loss {self.losses['train'][-1]}\n",
    "            val loss {self.losses['val'][-1]}\n",
    "            \"\"\",\n",
    "            \n",
    "            f\"\"\"\n",
    "            train dice score {self.dice_scores['train'][-1]}\n",
    "            val dice score {self.dice_scores['val'][-1]} \n",
    "            \"\"\", \n",
    "                  \n",
    "            f\"\"\"\n",
    "            train jaccard score {self.jaccard_scores['train'][-1]}\n",
    "            val jaccard score {self.jaccard_scores['val'][-1]}\n",
    "            \"\"\",\n",
    "        ]\n",
    "        \n",
    "        clear_output(True)\n",
    "        with plt.style.context(\"seaborn-dark-palette\"):\n",
    "            fig, axes = plt.subplots(3, 1, figsize=(8, 10))\n",
    "            for i, ax in enumerate(axes):\n",
    "                ax.plot(data[i]['val'], c=colors[0], label=\"val\")\n",
    "                ax.plot(data[i]['train'], c=colors[-1], label=\"train\")\n",
    "                ax.set_title(labels[i])\n",
    "                ax.legend(loc=\"upper right\")\n",
    "                \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "    def load_predtrain_model(self,\n",
    "                             state_path: str):\n",
    "        self.net.load_state_dict(torch.load(state_path))\n",
    "        print(\"Predtrain model loaded\")\n",
    "        \n",
    "    def _save_train_history(self):\n",
    "        \"\"\"writing model weights and training logs to files.\"\"\"\n",
    "        torch.save(self.net.state_dict(),\n",
    "                   f\"./logs2/last_epoch_model.pth\")\n",
    "\n",
    "        logs_ = [self.losses, self.dice_scores, self.jaccard_scores]\n",
    "        log_names_ = [\"_loss\", \"_dice\", \"_jaccard\"]\n",
    "        logs = [logs_[i][key] for i in list(range(len(logs_)))\n",
    "                         for key in logs_[i]]\n",
    "        log_names = [key+log_names_[i] \n",
    "                     for i in list(range(len(logs_))) \n",
    "                     for key in logs_[i]\n",
    "                    ]\n",
    "        pd.DataFrame(\n",
    "            dict(zip(log_names, logs))\n",
    "        ).to_csv(\"./logs2/train_log.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the UNet3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T10:57:13.316522Z",
     "iopub.status.busy": "2023-06-02T10:57:13.316185Z",
     "iopub.status.idle": "2023-06-02T10:57:13.700156Z",
     "shell.execute_reply": "2023-06-02T10:57:13.699170Z",
     "shell.execute_reply.started": "2023-06-02T10:57:13.316490Z"
    }
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Define the search space for hyperparameters\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-3, log=True)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [1, 2, 4])\n",
    "    num_epochs = trial.suggest_int(\"num_epochs\", 1, 5)\n",
    "    n_channels = trial.suggest_categorical(\"n_channels\", [8, 16, 24])\n",
    "    accumulation_steps = trial.suggest_categorical(\"accumulation_steps\", [2, 4, 6])\n",
    "\n",
    "    # Instantiate the model and the trainer with the sampled hyperparameters\n",
    "    model = AttentionUNet3D(in_channels=4, n_classes=3, n_channels=n_channels)\n",
    "    trainer = Trainer(net=model,\n",
    "                      dataset=BratsDataset,\n",
    "                      criterion=BCEDiceLoss(),\n",
    "                      lr=lr,\n",
    "                      accumulation_steps=accumulation_steps,\n",
    "                      batch_size=batch_size,\n",
    "                      fold=0,\n",
    "                      num_epochs=num_epochs,\n",
    "                      path_to_csv=config.path_to_csv)\n",
    "\n",
    "    # Train the model and get the validation score\n",
    "    trainer.run(early_stopping=True, patience=5, checkpoint_path=\"./test_checkpoints\")\n",
    "    val_dice_score = trainer.dice_scores[\"val\"][-1]\n",
    "\n",
    "    # Return the validation score (to be minimized)\n",
    "    return 1 - val_dice_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "# Create an Optuna study\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "\n",
    "# Optimize the objective function\n",
    "study.optimize(objective, n_trials=5)\n",
    "\n",
    "# Print the best hyperparameters and the corresponding validation score\n",
    "print(\"Best hyperparameters: \", study.best_params)\n",
    "print(\"Best validation dice score: \", 1 - study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.pretrained_model_path is not None:\n",
    "    trainer.load_predtrain_model(config.pretrained_model_path)\n",
    "    \n",
    "    # if need - load the logs.      \n",
    "    train_logs = pd.read_csv(config.train_logs_path)\n",
    "    trainer.losses[\"train\"] =  train_logs.loc[:, \"train_loss\"].to_list()\n",
    "    trainer.losses[\"val\"] =  train_logs.loc[:, \"val_loss\"].to_list()\n",
    "    trainer.dice_scores[\"train\"] = train_logs.loc[:, \"train_dice\"].to_list()\n",
    "    trainer.dice_scores[\"val\"] = train_logs.loc[:, \"val_dice\"].to_list()\n",
    "    trainer.jaccard_scores[\"train\"] = train_logs.loc[:, \"train_jaccard\"].to_list()\n",
    "    trainer.jaccard_scores[\"val\"] = train_logs.loc[:, \"val_jaccard\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T10:57:13.702167Z",
     "iopub.status.busy": "2023-06-02T10:57:13.701513Z",
     "iopub.status.idle": "2023-06-02T10:57:13.707006Z",
     "shell.execute_reply": "2023-06-02T10:57:13.705779Z",
     "shell.execute_reply.started": "2023-06-02T10:57:13.702132Z"
    }
   },
   "outputs": [],
   "source": [
    "# training time(t0) starts \n",
    "t0 = time.time() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T10:57:13.709299Z",
     "iopub.status.busy": "2023-06-02T10:57:13.708311Z",
     "iopub.status.idle": "2023-06-02T11:16:46.601836Z",
     "shell.execute_reply": "2023-06-02T11:16:46.600595Z",
     "shell.execute_reply.started": "2023-06-02T10:57:13.709266Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T11:16:46.604124Z",
     "iopub.status.busy": "2023-06-02T11:16:46.603757Z",
     "iopub.status.idle": "2023-06-02T11:16:46.609618Z",
     "shell.execute_reply": "2023-06-02T11:16:46.608605Z",
     "shell.execute_reply.started": "2023-06-02T11:16:46.604085Z"
    }
   },
   "outputs": [],
   "source": [
    "# total training time(tt) \n",
    "t1 = time.time()\n",
    "tt = t1 - t0 \n",
    "print(\"Training time : \",tt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model serialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A state dictionary contains only the learnable parameters.Whereas the entire model object includes the model architecture, optimizer state, and potentially other attributes. By saving only the state dictionary, you can significantly reduce the file size of the saved model.\n",
    "\n",
    "#### Therefore i'm serializing the state dictionary of the UNET3D model"
   ]
  },
  {
   "attachments": {
    "fdced627-60fc-4877-aed4-36dfcaa361b2.PNG": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![modelsave.PNG](attachment:fdced627-60fc-4877-aed4-36dfcaa361b2.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T11:16:46.612164Z",
     "iopub.status.busy": "2023-06-02T11:16:46.611422Z",
     "iopub.status.idle": "2023-06-02T11:16:46.712456Z",
     "shell.execute_reply": "2023-06-02T11:16:46.711516Z",
     "shell.execute_reply.started": "2023-06-02T11:16:46.612132Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'test_state_dict.pth')\n",
    "torch.save(model, 'test_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T11:16:46.714081Z",
     "iopub.status.busy": "2023-06-02T11:16:46.713735Z",
     "iopub.status.idle": "2023-06-02T11:16:46.967071Z",
     "shell.execute_reply": "2023-06-02T11:16:46.965957Z",
     "shell.execute_reply.started": "2023-06-02T11:16:46.714052Z"
    }
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainer performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T11:16:46.969696Z",
     "iopub.status.busy": "2023-06-02T11:16:46.968906Z",
     "iopub.status.idle": "2023-06-02T11:16:47.541622Z",
     "shell.execute_reply": "2023-06-02T11:16:47.540764Z",
     "shell.execute_reply.started": "2023-06-02T11:16:46.969661Z"
    }
   },
   "outputs": [],
   "source": [
    "# Loading the serialized model to avoid computation\n",
    "model = torch.load('./test_model.pth')\n",
    "\n",
    "# Turning on Evaluation mode of the model\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T11:16:47.543742Z",
     "iopub.status.busy": "2023-06-02T11:16:47.543389Z",
     "iopub.status.idle": "2023-06-02T11:16:47.559813Z",
     "shell.execute_reply": "2023-06-02T11:16:47.558828Z",
     "shell.execute_reply.started": "2023-06-02T11:16:47.543711Z"
    }
   },
   "outputs": [],
   "source": [
    "test_dataloader = get_dataloader(dataset=BratsDataset, path_to_csv='train_data.csv', phase=\"valid\", fold=1)\n",
    "len(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T11:16:47.561661Z",
     "iopub.status.busy": "2023-06-02T11:16:47.561301Z",
     "iopub.status.idle": "2023-06-02T11:17:50.451087Z",
     "shell.execute_reply": "2023-06-02T11:17:50.449858Z",
     "shell.execute_reply.started": "2023-06-02T11:16:47.561630Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "gc.collect() \n",
    "def compute_metrics(model, dataloader, threshold=0.33):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.eval()\n",
    "\n",
    "    true_positives = 0\n",
    "    false_positives = 0\n",
    "    true_negatives = 0\n",
    "    false_negatives = 0\n",
    "\n",
    "    counter = 0  # Counter to keep track of the number of entries processed\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculations to save memory\n",
    "        for data in dataloader:\n",
    "            \n",
    "            images, targets = data['image'], data['mask']\n",
    "            images = images.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            logits = model(images)\n",
    "            probabilities = torch.sigmoid(logits)\n",
    "            predictions = (probabilities >= threshold).float()\n",
    "\n",
    "            # Compute binary segmentation metrics\n",
    "            true_positives += torch.sum((predictions == 1) & (targets == 1)).item()\n",
    "            false_positives += torch.sum((predictions == 1) & (targets == 0)).item()\n",
    "            true_negatives += torch.sum((predictions == 0) & (targets == 0)).item()\n",
    "            false_negatives += torch.sum((predictions == 0) & (targets == 1)).item()\n",
    "\n",
    "            counter += 1\n",
    "\n",
    "            # Free memory by clearing intermediate variables\n",
    "            del images, targets, logits, probabilities, predictions\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    return true_positives , false_positives , true_negatives , false_negatives\n",
    "\n",
    "tp , fp , tn , fn  = compute_metrics(model, test_dataloader, threshold=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T11:17:50.453243Z",
     "iopub.status.busy": "2023-06-02T11:17:50.452853Z",
     "iopub.status.idle": "2023-06-02T11:17:50.460603Z",
     "shell.execute_reply": "2023-06-02T11:17:50.459276Z",
     "shell.execute_reply.started": "2023-06-02T11:17:50.453202Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"True positives : {tp}\")\n",
    "print(f\"False positives : {fp}\")\n",
    "print(f\"True Negatives : {tn}\")\n",
    "print(f\"False Negatives : {fn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T11:17:50.462764Z",
     "iopub.status.busy": "2023-06-02T11:17:50.461881Z",
     "iopub.status.idle": "2023-06-02T11:17:50.737465Z",
     "shell.execute_reply": "2023-06-02T11:17:50.736546Z",
     "shell.execute_reply.started": "2023-06-02T11:17:50.462733Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_confusion_matrix(tp, fp, tn, fn):\n",
    "    # Create confusion matrix array\n",
    "    confusion_matrix = np.array([[tn, fp], [fn, tp]])\n",
    "\n",
    "    # Set up labels for matrix\n",
    "    labels = ['True ', 'False ']\n",
    "\n",
    "    # Create color map\n",
    "    cmap = plt.cm.Blues\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plt.imshow(confusion_matrix, interpolation='nearest', cmap=cmap)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.colorbar()\n",
    "\n",
    "    # Add labels to matrix cells\n",
    "    thresh = confusion_matrix.max() / 2.\n",
    "    for i, j in np.ndindex(confusion_matrix.shape):\n",
    "        plt.text(j, i, format(confusion_matrix[i, j], 'd'), horizontalalignment='center', color='white' if confusion_matrix[i, j] > thresh else 'black')\n",
    "\n",
    "    # Set tick labels\n",
    "    tick_marks = np.arange(len(labels))\n",
    "    plt.xticks(tick_marks, labels, rotation=45)\n",
    "    plt.yticks(tick_marks, labels)\n",
    "\n",
    "    # Set axis labels\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.ylabel('True label')\n",
    "\n",
    "    # Show plot\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion_matrix(tp, fp, tn, fn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T11:17:50.740800Z",
     "iopub.status.busy": "2023-06-02T11:17:50.738835Z",
     "iopub.status.idle": "2023-06-02T11:17:50.746357Z",
     "shell.execute_reply": "2023-06-02T11:17:50.745377Z",
     "shell.execute_reply.started": "2023-06-02T11:17:50.740765Z"
    }
   },
   "outputs": [],
   "source": [
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T11:17:50.748424Z",
     "iopub.status.busy": "2023-06-02T11:17:50.747603Z",
     "iopub.status.idle": "2023-06-02T11:17:50.759339Z",
     "shell.execute_reply": "2023-06-02T11:17:50.758413Z",
     "shell.execute_reply.started": "2023-06-02T11:17:50.748391Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Accuracy : {accuracy*100}\")\n",
    "print(f\"Precision : {precision*100}\")\n",
    "print(f\"Recall : {recall*100}\")\n",
    "print(f\"F1 Score : {f1_score*100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T11:17:50.761385Z",
     "iopub.status.busy": "2023-06-02T11:17:50.760952Z",
     "iopub.status.idle": "2023-06-02T11:17:50.769676Z",
     "shell.execute_reply": "2023-06-02T11:17:50.768779Z",
     "shell.execute_reply.started": "2023-06-02T11:17:50.761252Z"
    }
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import numpy as np\n",
    "# from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# gc.collect()\n",
    "\n",
    "# def compute_metrics(model, dataloader, num_entries, threshold=0.33):\n",
    "#     device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#     predictions = []\n",
    "\n",
    "#     # Counter to keep track of the number of entries processed\n",
    "#     counter = 0  \n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for data in dataloader:\n",
    "#             if counter >= num_entries:\n",
    "#                 break  # Stop processing entries if the desired number is reached\n",
    "\n",
    "#             images, targets = data['image'], data['mask']\n",
    "#             images = images.to(device)\n",
    "#             targets = targets.to(device)\n",
    "\n",
    "#             logits = model(images)\n",
    "#             probabilities = torch.sigmoid(logits)\n",
    "#             prediction = (probabilities >= threshold).float()\n",
    "\n",
    "#             prediction =  prediction.cpu()\n",
    "#             targets = targets.cpu()\n",
    "            \n",
    "#             predictions.append(prediction)\n",
    "\n",
    "#             model.zero_grad()\n",
    "#             del images, targets, logits, probabilities, prediction\n",
    "#             torch.cuda.empty_cache()\n",
    "\n",
    "#             counter += 1\n",
    "\n",
    "#     # Compute confusion matrix\n",
    "#     y_true = np.concatenate([targets.cpu() for data in dataloader for targets in data['mask']])\n",
    "#     y_pred = np.concatenate([prediction.cpu() for data in dataloader for prediction in predictions])\n",
    "    \n",
    "#     # y_true = np.concatenate([targets for targets in dataloader.dataset])\n",
    "#     # y_pred = np.concatenate([predictions for predictions in predictions])\n",
    "\n",
    "    \n",
    "#     cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "#     # Compute classification report\n",
    "#     class_names = ['Background', 'Tumor']\n",
    "#     report = classification_report(y_true, y_pred, target_names=class_names)\n",
    "\n",
    "#     # Return evaluation metrics, confusion matrix, and classification report\n",
    "#     evaluation_results = {\n",
    "#         'Confusion Matrix': cm,\n",
    "#         'Classification Report': report\n",
    "#     }\n",
    "\n",
    "#     return evaluation_results\n",
    "\n",
    "# num_entries = 5  # Specify the number of entries to evaluate\n",
    "# evaluation_results = compute_metrics(model, test_dataloader, num_entries, threshold=0.33)\n",
    "\n",
    "# # Print the evaluation results\n",
    "# for metric, value in evaluation_results.items():\n",
    "#     print(f'{metric}: {value}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T11:17:50.771487Z",
     "iopub.status.busy": "2023-06-02T11:17:50.771065Z",
     "iopub.status.idle": "2023-06-02T11:17:50.783313Z",
     "shell.execute_reply": "2023-06-02T11:17:50.782660Z",
     "shell.execute_reply.started": "2023-06-02T11:17:50.771456Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_scores_per_classes(model,          # model which is UNeT3D \n",
    "                               dataloader,     # tuple consisting of ( id , image tensor , mask tensor )\n",
    "                               classes):       # classes : WT , TC , ET \n",
    "    \"\"\"\n",
    "    Compute Dice and Jaccard coefficients for each class.\n",
    "    Params:\n",
    "        model: neural net for make predictions.\n",
    "        dataloader: dataset object to load data from.\n",
    "        classes: list with classes.\n",
    "        Returns: dictionaries with dice and jaccard coefficients for each class for each slice.\n",
    "    \"\"\"\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    dice_scores_per_classes = {key: list() for key in classes}\n",
    "    iou_scores_per_classes = {key: list() for key in classes}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(dataloader):\n",
    "            imgs, targets = data['image'], data['mask']\n",
    "            imgs, targets = imgs.to(device), targets.to(device)\n",
    "            logits = model(imgs)\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            targets = targets.detach().cpu().numpy()\n",
    "            \n",
    "            # Now finding the overlap between the raw prediction i.e. logit & the mask i.e. target & finding the dice & iou scores \n",
    "            dice_scores = dice_coef_metric_per_classes(logits, targets)\n",
    "            iou_scores = jaccard_coef_metric_per_classes(logits, targets)\n",
    "\n",
    "            # storing both dice & iou scores in the list declared \n",
    "            for key in dice_scores.keys():\n",
    "                dice_scores_per_classes[key].extend(dice_scores[key])\n",
    "\n",
    "            for key in iou_scores.keys():\n",
    "                iou_scores_per_classes[key].extend(iou_scores[key])\n",
    "\n",
    "    return dice_scores_per_classes, iou_scores_per_classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T11:17:50.785101Z",
     "iopub.status.busy": "2023-06-02T11:17:50.784454Z",
     "iopub.status.idle": "2023-06-02T11:17:50.812207Z",
     "shell.execute_reply": "2023-06-02T11:17:50.811304Z",
     "shell.execute_reply.started": "2023-06-02T11:17:50.785068Z"
    }
   },
   "outputs": [],
   "source": [
    "val_dataloader = get_dataloader(BratsDataset, 'train_data.csv', phase='valid', fold=0)\n",
    "len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T11:17:50.813819Z",
     "iopub.status.busy": "2023-06-02T11:17:50.813439Z",
     "iopub.status.idle": "2023-06-02T11:17:50.820579Z",
     "shell.execute_reply": "2023-06-02T11:17:50.819444Z",
     "shell.execute_reply.started": "2023-06-02T11:17:50.813771Z"
    }
   },
   "outputs": [],
   "source": [
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T11:17:50.822519Z",
     "iopub.status.busy": "2023-06-02T11:17:50.822114Z",
     "iopub.status.idle": "2023-06-02T11:19:01.517016Z",
     "shell.execute_reply": "2023-06-02T11:19:01.515797Z",
     "shell.execute_reply.started": "2023-06-02T11:17:50.822488Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "dice_scores_per_classes, iou_scores_per_classes = compute_scores_per_classes(\n",
    "    model, val_dataloader, ['WT', 'TC', 'ET']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T11:19:01.519594Z",
     "iopub.status.busy": "2023-06-02T11:19:01.518950Z",
     "iopub.status.idle": "2023-06-02T11:19:01.545354Z",
     "shell.execute_reply": "2023-06-02T11:19:01.544282Z",
     "shell.execute_reply.started": "2023-06-02T11:19:01.519552Z"
    }
   },
   "outputs": [],
   "source": [
    "dice_df = pd.DataFrame(dice_scores_per_classes)\n",
    "dice_df.columns = ['WT dice', 'TC dice', 'ET dice']\n",
    "\n",
    "iou_df = pd.DataFrame(iou_scores_per_classes)\n",
    "iou_df.columns = ['WT jaccard', 'TC jaccard', 'ET jaccard']\n",
    "# CONCAT BOTH THE COLUMNS ALONG AXIS 1 & SORT THE TWO \n",
    "val_metics_df = pd.concat([dice_df, iou_df], axis=1, sort=True)\n",
    "val_metics_df = val_metics_df.loc[:, ['WT dice', 'WT jaccard', \n",
    "                                      'TC dice', 'TC jaccard', \n",
    "                                      'ET dice', 'ET jaccard']]\n",
    "val_metics_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T11:19:01.547635Z",
     "iopub.status.busy": "2023-06-02T11:19:01.547241Z",
     "iopub.status.idle": "2023-06-02T11:19:02.369507Z",
     "shell.execute_reply": "2023-06-02T11:19:02.368461Z",
     "shell.execute_reply.started": "2023-06-02T11:19:01.547600Z"
    }
   },
   "outputs": [],
   "source": [
    "colors = ['#35FCFF', '#FF355A', '#96C503', '#C5035B', '#28B463', '#35FFAF']\n",
    "palette = sns.color_palette(colors, 6)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6));\n",
    "sns.barplot(x=val_metics_df.mean().index, y=val_metics_df.mean(), palette=palette, ax=ax);\n",
    "ax.set_xticklabels(val_metics_df.columns, fontsize=14, rotation=15);\n",
    "ax.set_title(\"Dice and Jaccard Coefficients from Validation\", fontsize=20)\n",
    "\n",
    "for idx, p in enumerate(ax.patches):\n",
    "        percentage = '{:.1f}%'.format(100 * val_metics_df.mean().values[idx])\n",
    "        x = p.get_x() + p.get_width() / 2 - 0.15\n",
    "        y = p.get_y() + p.get_height()\n",
    "        ax.annotate(percentage, (x, y), fontsize=15, fontweight=\"bold\")\n",
    "\n",
    "fig.savefig(\"result1.png\", format=\"png\",  pad_inches=0.2, transparent=False, bbox_inches='tight')\n",
    "fig.savefig(\"result1.svg\", format=\"svg\",  pad_inches=0.2, transparent=False, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing the brain tumour segmented masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T11:19:02.371467Z",
     "iopub.status.busy": "2023-06-02T11:19:02.370846Z",
     "iopub.status.idle": "2023-06-02T11:19:02.380729Z",
     "shell.execute_reply": "2023-06-02T11:19:02.379812Z",
     "shell.execute_reply.started": "2023-06-02T11:19:02.371433Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_results(model,\n",
    "                    dataloader,\n",
    "                    treshold=0.33):\n",
    "\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    results = {\"Id\": [],\"image\": [], \"GT\": [],\"Prediction\": []}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(dataloader):\n",
    "            id_, imgs, targets = data['Id'], data['image'], data['mask']\n",
    "            imgs, targets = imgs.to(device), targets.to(device)\n",
    "            logits = model(imgs)\n",
    "            probs = torch.sigmoid(logits)\n",
    "            \n",
    "            predictions = (probs >= treshold).float()\n",
    "            predictions =  predictions.cpu()\n",
    "            targets = targets.cpu()\n",
    "            \n",
    "            results[\"Id\"].append(id_)\n",
    "            results[\"image\"].append(imgs.cpu())\n",
    "            results[\"GT\"].append(targets)\n",
    "            results[\"Prediction\"].append(predictions)\n",
    "            \n",
    "            # only 5 pars\n",
    "            if (i > 5):\n",
    "                return results\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T11:19:02.382682Z",
     "iopub.status.busy": "2023-06-02T11:19:02.382264Z",
     "iopub.status.idle": "2023-06-02T11:19:02.393455Z",
     "shell.execute_reply": "2023-06-02T11:19:02.392573Z",
     "shell.execute_reply.started": "2023-06-02T11:19:02.382649Z"
    }
   },
   "outputs": [],
   "source": [
    "# prediction time starts(p0) \n",
    "p0 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T11:19:02.395449Z",
     "iopub.status.busy": "2023-06-02T11:19:02.395094Z",
     "iopub.status.idle": "2023-06-02T11:19:30.046752Z",
     "shell.execute_reply": "2023-06-02T11:19:30.045084Z",
     "shell.execute_reply.started": "2023-06-02T11:19:02.395416Z"
    }
   },
   "outputs": [],
   "source": [
    "results = compute_results(\n",
    "    model, val_dataloader, 0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T11:19:30.054833Z",
     "iopub.status.busy": "2023-06-02T11:19:30.054351Z",
     "iopub.status.idle": "2023-06-02T11:19:30.067825Z",
     "shell.execute_reply": "2023-06-02T11:19:30.066749Z",
     "shell.execute_reply.started": "2023-06-02T11:19:30.054784Z"
    }
   },
   "outputs": [],
   "source": [
    "# total prediction time(pt) \n",
    "p1 = time.time()\n",
    "pt = p1 - p0 \n",
    "print(\"Model prediction time ; \",pt ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T11:19:30.069663Z",
     "iopub.status.busy": "2023-06-02T11:19:30.069104Z",
     "iopub.status.idle": "2023-06-02T11:19:30.087003Z",
     "shell.execute_reply": "2023-06-02T11:19:30.085993Z",
     "shell.execute_reply.started": "2023-06-02T11:19:30.069630Z"
    }
   },
   "outputs": [],
   "source": [
    "for id_, img, gt, prediction in zip(results['Id'][4:],\n",
    "                    results['image'][4:],\n",
    "                    results['GT'][4:],\n",
    "                    results['Prediction'][4:]\n",
    "                    ):\n",
    "    \n",
    "    print(id_)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the predicted segmented masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T11:19:30.093047Z",
     "iopub.status.busy": "2023-06-02T11:19:30.091089Z",
     "iopub.status.idle": "2023-06-02T11:19:41.699301Z",
     "shell.execute_reply": "2023-06-02T11:19:41.698425Z",
     "shell.execute_reply.started": "2023-06-02T11:19:30.093011Z"
    }
   },
   "outputs": [],
   "source": [
    "show_result = ShowResult()\n",
    "show_result.plot(img, gt, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D SCATTER PLOT OF THE BRAIN TUMOUR WITH : \n",
    "#### 1. necrotic and non-enhancing tumor core (NCR/NET — label 1)\n",
    "#### 2. peritumoral edema (ED — label 2)\n",
    "#### 3. GD-enhancing tumor (ET — label 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T11:19:41.701384Z",
     "iopub.status.busy": "2023-06-02T11:19:41.700847Z",
     "iopub.status.idle": "2023-06-02T11:19:44.162480Z",
     "shell.execute_reply": "2023-06-02T11:19:44.161514Z",
     "shell.execute_reply.started": "2023-06-02T11:19:41.701353Z"
    }
   },
   "outputs": [],
   "source": [
    "class ImageReader:\n",
    "    def __init__(self, root:str, img_size:int=256, normalize:bool=False, single_class:bool=False):\n",
    "        pad_size = 256 if img_size > 256 else 224\n",
    "        self.resize = A.Compose(\n",
    "            [\n",
    "                A.PadIfNeeded(min_height=pad_size, min_width=pad_size, value=0),\n",
    "                A.Resize(img_size, img_size)\n",
    "            ]\n",
    "        )\n",
    "        self.normalize=normalize\n",
    "        self.single_class=single_class\n",
    "        self.root=root\n",
    "        \n",
    "    def read_file(self, path:str) -> dict:\n",
    "        scan_type = path.split('_')[-1]\n",
    "        raw_image = nib.load(path).get_fdata()\n",
    "        raw_mask = nib.load(path.replace(scan_type, 'seg.nii')).get_fdata()\n",
    "        processed_frames, processed_masks = [], []\n",
    "        for frame_idx in range(raw_image.shape[2]):\n",
    "            frame = raw_image[:, :, frame_idx]\n",
    "            mask = raw_mask[:, :, frame_idx]\n",
    "            if self.normalize:\n",
    "                if frame.max() > 0:\n",
    "                    frame = frame/frame.max()\n",
    "                frame = frame.astype(np.float32)\n",
    "            else:\n",
    "                frame = frame.astype(np.uint8)\n",
    "            resized = self.resize(image=frame, mask=mask)\n",
    "            processed_frames.append(resized['image'])\n",
    "            processed_masks.append(1*(resized['mask'] > 0) if self.single_class else resized['mask'])\n",
    "        return {\n",
    "            'scan': np.stack(processed_frames, 0),\n",
    "            'segmentation': np.stack(processed_masks, 0),\n",
    "            'orig_shape': raw_image.shape\n",
    "        }\n",
    "    \n",
    "    def load_patient_scan(self, idx:int, scan_type:str='flair') -> dict:\n",
    "        patient_id = str(1).zfill(3) \n",
    "        scan_filename = f'{self.root}/BraTS20_Training_{patient_id}/BraTS20_Training_{patient_id}_{scan_type}.nii'\n",
    "        return self.read_file(scan_filename)\n",
    "    \n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import plotly\n",
    "\n",
    "\n",
    "def generate_3d_scatter(\n",
    "    x:np.array, y:np.array, z:np.array, colors:np.array,\n",
    "    size:int=3, opacity:float=0.2, scale:str='Teal',\n",
    "    hover:str='skip', name:str='MRI'\n",
    ") -> go.Scatter3d:\n",
    "    return go.Scatter3d(\n",
    "        x=x, y=y, z=z,\n",
    "        mode='markers', hoverinfo=hover,\n",
    "        marker = dict(\n",
    "            size=size, opacity=opacity,\n",
    "            color=colors, colorscale=scale\n",
    "        ),\n",
    "        name=name\n",
    "    )\n",
    "\n",
    "\n",
    "class ImageViewer3d():\n",
    "    def __init__(\n",
    "        self, reader:ImageReader, mri_downsample:int=10, mri_colorscale:str='Ice'\n",
    "    ) -> None:\n",
    "        self.reader = reader\n",
    "        self.mri_downsample = mri_downsample\n",
    "        self.mri_colorscale = mri_colorscale\n",
    "\n",
    "    def load_clean_mri(self, image:np.array, orig_dim:int) -> dict:\n",
    "        shape_offset = image.shape[1]/orig_dim\n",
    "        z, x, y = (image > 0).nonzero()\n",
    "        # only (1/mri_downsample) is sampled for the resulting image\n",
    "        x, y, z = x[::self.mri_downsample], y[::self.mri_downsample], z[::self.mri_downsample]\n",
    "        colors = image[z, x, y]\n",
    "        return dict(x=x/shape_offset, y=y/shape_offset, z=z, colors=colors)\n",
    "    def load_tumor_segmentation(self, image:np.array, orig_dim:int) -> dict:\n",
    "        tumors = {}\n",
    "        shape_offset = image.shape[1]/orig_dim\n",
    "        # 1/1, 1/3 si 1/5 pixeli pentru clasele tumorii  1(nucleu necrotic), 2(edem) si 4(tumoare de amplificare)\n",
    "        sampling = {\n",
    "            1: 1, 2: 3, 4: 5\n",
    "        }\n",
    "        for class_idx in sampling:\n",
    "            z, x, y = (image == class_idx).nonzero()\n",
    "            x, y, z = x[::sampling[class_idx]], y[::sampling[class_idx]], z[::sampling[class_idx]]\n",
    "            tumors[class_idx] = dict(\n",
    "                x=x/shape_offset, y=y/shape_offset, z=z,\n",
    "                colors=class_idx/4\n",
    "            )\n",
    "        return tumors\n",
    "    def collect_patient_data(self, scan:dict) -> tuple:\n",
    "        clean_mri = self.load_clean_mri(scan['scan'], scan['orig_shape'][0])\n",
    "        tumors = self.load_tumor_segmentation(scan['segmentation'], scan['orig_shape'][0])\n",
    "        markers_created = clean_mri['x'].shape[0] + sum(tumors[class_idx]['x'].shape[0] for class_idx in tumors)\n",
    "        return [\n",
    "            generate_3d_scatter(**clean_mri, scale=self.mri_colorscale, opacity=0.3, hover='skip', name='Brain MRI'),\n",
    "            generate_3d_scatter(**tumors[1], opacity=0.90, hover='all', name='Necrotic tumor core'),\n",
    "            generate_3d_scatter(**tumors[2], opacity=0.05, hover='all', name='Peritumoral invaded tissue'),\n",
    "            generate_3d_scatter(**tumors[4], opacity=0.30, hover='all', name='GD-enhancing tumor'),\n",
    "        ], markers_created\n",
    "    def get_3d_scan(self, patient_idx:int, scan_type:str='flair') -> go.Figure:\n",
    "        scan = self.reader.load_patient_scan(patient_idx, scan_type)\n",
    "        data, num_markers = self.collect_patient_data(scan)\n",
    "        fig = go.Figure(data=data)\n",
    "        fig.update_layout(\n",
    "            title=f\"[Patient id:{patient_idx}] brain MRI scan ({num_markers} points)\",\n",
    "            legend_title=\"Pixel class (click to enable/disable)\",\n",
    "            font=dict(\n",
    "                family=\"Courier New, monospace\",\n",
    "                size=14,\n",
    "            ),\n",
    "            margin=dict(\n",
    "                l=0,r=0,b=0,t=30\n",
    "            ),\n",
    "            legend=dict(itemsizing='constant')\n",
    "        )\n",
    "        return fig\n",
    "\n",
    "# tumour visualization time starts(tv0)\n",
    "tv0 = time.time() \n",
    "reader = ImageReader(config.train_root_dir, img_size=128, normalize=True, single_class=False)\n",
    "viewer = ImageViewer3d(reader, mri_downsample=25)\n",
    "\n",
    "fig = viewer.get_3d_scan(250, 'flair')\n",
    "plotly.offline.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T11:19:44.164764Z",
     "iopub.status.busy": "2023-06-02T11:19:44.163865Z",
     "iopub.status.idle": "2023-06-02T11:19:44.171631Z",
     "shell.execute_reply": "2023-06-02T11:19:44.169083Z",
     "shell.execute_reply.started": "2023-06-02T11:19:44.164732Z"
    }
   },
   "outputs": [],
   "source": [
    "# total tumour visualization time(tvt) \n",
    "tv1 = time.time() \n",
    "tvt = tv1 - tv0 \n",
    "print(\"3D Scatter plot time : \", tvt ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T11:19:44.173814Z",
     "iopub.status.busy": "2023-06-02T11:19:44.173099Z",
     "iopub.status.idle": "2023-06-02T11:19:44.251137Z",
     "shell.execute_reply": "2023-06-02T11:19:44.250013Z",
     "shell.execute_reply.started": "2023-06-02T11:19:44.173773Z"
    }
   },
   "outputs": [],
   "source": [
    "import plotly.offline as pyo\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Save the scatter plot as an image file\n",
    "filename = './scatter_plot_test.png'  # Replace with your desired file path\n",
    "pyo.plot(fig, filename=filename, auto_open=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T11:20:06.658430Z",
     "iopub.status.busy": "2023-06-02T11:20:06.657524Z",
     "iopub.status.idle": "2023-06-02T11:20:06.664945Z",
     "shell.execute_reply": "2023-06-02T11:20:06.663834Z",
     "shell.execute_reply.started": "2023-06-02T11:20:06.658386Z"
    }
   },
   "outputs": [],
   "source": [
    "# total code wall time(cwt)\n",
    "cw1 = time.time() \n",
    "cwt = cw1 - cw0 \n",
    "print(\"Total code wall time / running time : \", cwt )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code running time evalution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T11:20:06.916348Z",
     "iopub.status.busy": "2023-06-02T11:20:06.916009Z",
     "iopub.status.idle": "2023-06-02T11:20:06.946871Z",
     "shell.execute_reply": "2023-06-02T11:20:06.945798Z",
     "shell.execute_reply.started": "2023-06-02T11:20:06.916318Z"
    }
   },
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "# Define the variables and their respective values\n",
    "variables = ['Data loading', 'data preprocessing', 'Stratification', 'Model training', 'tumour predction', 'tumour visualization', ' total code wall time']\n",
    "values = [dlt, dppt, skft, tt, pt, tvt, cwt]  # Assign the actual values to these variables\n",
    "\n",
    "# Create a list of lists containing the variables and values\n",
    "table_data = [[var, val] for var, val in zip(variables, values)]\n",
    "\n",
    "# Specify the table headers\n",
    "headers = ['Times', 'Value']\n",
    "\n",
    "# Generate the table using tabulate\n",
    "table = tabulate(table_data, headers, tablefmt='grid')\n",
    "\n",
    "# Print the table\n",
    "print(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T11:20:07.047399Z",
     "iopub.status.busy": "2023-06-02T11:20:07.047079Z",
     "iopub.status.idle": "2023-06-02T11:20:07.371791Z",
     "shell.execute_reply": "2023-06-02T11:20:07.370862Z",
     "shell.execute_reply.started": "2023-06-02T11:20:07.047373Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the variables and their respective values (running times)\n",
    "variables = ['Data loading', 'data preprocessing', 'Stratification', 'Model training', 'tumour predction', 'tumour visualization', ' total code wall time']\n",
    "values = [dlt, dppt, skft, tt, pt, tvt, cwt]  # Assign the actual running times to these variables\n",
    "\n",
    "# Create a bar chart\n",
    "plt.figure(figsize=(10, 6))  # Set the figure size\n",
    "plt.bar(variables, values)  # Plot the bar chart\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Variables')  # X-axis label\n",
    "plt.ylabel('Running Time')  # Y-axis label\n",
    "plt.title('Running Times of Variables')  # Chart title\n",
    "\n",
    "# Display the bar chart\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
